# -*- coding: utf-8 -*-
"""Assignment_4 makhijani.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f6hZww9nrOptP4Xlhr0pEUaxf_TWj2Ad
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from past.builtins import xrange
import datetime
from datetime import timedelta
from pandas import DataFrame
from scipy.fftpack import fft, ifft,dct
import pywt
import scipy.stats as stats
from sklearn.metrics import classification_report, accuracy_score, make_scorer

import warnings
warnings.filterwarnings("ignore")

insulin_data1=pd.read_csv('InsulinData.csv',low_memory=False, parse_dates = [['Date', 'Time']])[['Date_Time', 'BWZ Estimate (U)']]
cgm_data1=pd.read_csv('CGMData.csv',low_memory=False,parse_dates = [['Date', 'Time']])

def trimData(insulin_data, cgm_data):
    min_insulin_time = min(insulin_data['Date_Time'])
    min_cgm_time = min(cgm_data['Date_Time'])
    min_timestamp = max(min_insulin_time, min_cgm_time)
    max_insulin_time = max(insulin_data['Date_Time'])
    max_cgm_time = max(cgm_data['Date_Time'])
    max_timestamp = min(max_insulin_time, max_cgm_time)
    insulin_trimmed = insulin_data[(insulin_data['Date_Time'] >= min_timestamp)]
    insulin_trimmed = insulin_trimmed.reset_index(drop=True)
    insulin_trimmed = insulin_data[(insulin_data['Date_Time'] <= max_timestamp)]
    insulin_trimmed = insulin_trimmed.reset_index(drop=True)
    cgm_trimmed = cgm_data[(cgm_data['Date_Time'] >= min_timestamp)]
    cgm_trimmed = cgm_trimmed.reset_index(drop=True)
    cgm_trimmed = cgm_data[(cgm_data['Date_Time'] <= max_timestamp)]
    cgm_trimmed = cgm_trimmed.reset_index(drop=True)
    return insulin_trimmed, cgm_trimmed

insulin_data1_trimmed, cgm_data1_trimmed = trimData(insulin_data1, cgm_data1)

Bool_carbinput_data1=pd.notnull(insulin_data1_trimmed['BWZ Estimate (U)'])
insuline_data_ext1=insulin_data1_trimmed[Bool_carbinput_data1]
insuline_data_ext1 = insuline_data_ext1[insuline_data_ext1['BWZ Estimate (U)'] != 0].sort_values(by=['Date_Time'], ignore_index = True)
insuline_data_ext1 = insuline_data_ext1.reset_index(drop=True)

def extract_meal_cgm_timestamps(meal_dataframe):
    meal_data = []
    time_val = []
    meal_len = len(meal_dataframe)-1
    for row in range(0,meal_len):
        new_time = meal_dataframe.at[row, 'Date_Time'] + timedelta(hours = 2)
        if(new_time > meal_dataframe.at[row+1, 'Date_Time']):
           continue
        else:
             meal_data.append(meal_dataframe.at[row, 'Date_Time'])
             time_val.append(meal_dataframe.at[row, 'BWZ Estimate (U)'],)
    meal_dataframe_fin = pd.DataFrame(meal_data)
    meal_dataframe_fin['val'] = time_val
    return meal_dataframe_fin

# result = []
meal_data1 = extract_meal_cgm_timestamps(insuline_data_ext1)
print(meal_data1)

cgm_data1_trimmed['Sensor Glucose (mg/dL)'] = cgm_data1_trimmed['Sensor Glucose (mg/dL)'].interpolate(method = 'linear')

cgm_data1_trimmed = cgm_data1_trimmed[['Date_Time','Sensor Glucose (mg/dL)']]
cgm_data1_trimmed = cgm_data1_trimmed.reindex(index=cgm_data1_trimmed.index[::-1])
cgm_data1_trimmed = cgm_data1_trimmed.reset_index(drop=True)

def meal_cgm_extraction(meal_cgm_dataframe, cgmdata):
    list1 = ['cgm_val'+str(x) for x in range(30)]
    meal_data = pd.DataFrame(columns = list1)
    next_hit_list = []
    for id in meal_cgm_dataframe.index:
        dict1 = dict()
        data_sets = cgmdata[cgmdata['Date_Time'] >= meal_cgm_dataframe[0][id]]
        data_set_list = list(cgmdata.loc[data_sets.index[0]-6: data_sets.index[0]+23, 'Sensor Glucose (mg/dL)'].values)
        next_hit_list.append(cgmdata.loc[data_sets.index[0], 'Sensor Glucose (mg/dL)'])
        cgm_list=[]
        for id1, cgm_val in enumerate(data_set_list):
            cgm_list.append(cgm_val)
            for cgm in cgm_list:
              dict1[list1[id1]] = cgm_val
        meal_data = meal_data.append(dict1, ignore_index = True)
    meal_data['val']=list(meal_cgm_dataframe['val'])
    return meal_data,next_hit_list

cgm_meal1,next_hit_list = meal_cgm_extraction(meal_data1, cgm_data1_trimmed)
meal_cgm_master = cgm_meal1.reset_index(drop=True)
meal_cgm_master_list = meal_cgm_master.values.tolist()

meal_list_fin = []
meal_df = meal_cgm_master.drop(columns=['val'])
print(meal_df)
meal_list = meal_df.values.tolist()
for row in meal_list:
  for i in row:
    meal_list_fin.append(i)
max_val = max(meal_list_fin) 
min_val = min(meal_list_fin)
print(min_val)
print(max_val,min_val)
bin_size=int(max_val)//20
bins=range(bin_size)
dict1={}
for i in range(0,len(bins)-1):
  if i ==0:
    dict1[i]=min_val
  else:
    dict1[i]=dict1[i-1]+20
dict1.pop(0)
print(dict1)

print(dict1)
b_max = meal_df.max(axis=1)
b_max_list = b_max.values.tolist()
print(b_max_list)
b_max_binlist=[]
list1 = list(dict1.values())
print(list1)
for i in b_max_list:
  if i<=list1[0]:
    b_max_binlist.append(1)
  elif i<=list1[1]:
    b_max_binlist.append(2)
  elif i<=list1[2]:
    b_max_binlist.append(3)
  elif i<=list1[3]:
    b_max_binlist.append(4)
  elif i<=list1[4]:
    b_max_binlist.append(5)
  elif i<=list1[5]:
    b_max_binlist.append(6)
  elif i<=list1[6]:
    b_max_binlist.append(7)
  elif i<=list1[7]:
    b_max_binlist.append(8)
  elif i<=list1[8]:
    b_max_binlist.append(9)
  elif i<=list1[9]:
    b_max_binlist.append(10)
  elif i<=list1[10]:
    b_max_binlist.append(11)
  elif i<=list1[11]:
    b_max_binlist.append(12)
  elif i<=list1[12]:
    b_max_binlist.append(13)
  elif i<=list1[13]:
    b_max_binlist.append(14)
  elif i<=list1[14]:
    b_max_binlist.append(15)
  elif i<=list1[15]:
    b_max_binlist.append(16)
  elif i<=list1[16]:
    b_max_binlist.append(17)
  elif i<=list1[17]:
    b_max_binlist.append(18)
print(len(b_max_binlist))    
meal_cgm_master['B_max']=b_max_binlist

b_min_binlist = []
for j in next_hit_list:
  i=int(j)
  if i<=list1[0]:
    b_min_binlist.append(1)
  elif i<=list1[1]:
    b_min_binlist.append(2)
  elif i<=list1[2]:
    b_min_binlist.append(3)
  elif i<=list1[3]:
    b_min_binlist.append(4)
  elif i<=list1[4]:
    b_min_binlist.append(5)
  elif i<=list1[5]:
    b_min_binlist.append(6)
  elif i<=list1[6]:
    b_min_binlist.append(7)
  elif i<=list1[7]:
    b_min_binlist.append(8)
  elif i<=list1[8]:
    b_min_binlist.append(9)
  elif i<=list1[9]:
    b_min_binlist.append(10)
  elif i<=list1[10]:
    b_min_binlist.append(11)
  elif i<=list1[11]:
    b_min_binlist.append(12)
  elif i<=list1[12]:
    b_min_binlist.append(13)
  elif i<=list1[13]:
    b_min_binlist.append(14)
  elif i<=list1[14]:
    b_min_binlist.append(15)
  elif i<=list1[15]:
    b_min_binlist.append(16)
  elif i<=list1[16]:
    b_min_binlist.append(17)
  elif i<=list1[17]:
    b_min_binlist.append(18)
print(len(b_min_binlist),b_min_binlist)

meal_cgm_master['B_max']=b_max_binlist 
meal_cgm_master['B_min']=b_min_binlist

meal_cgm_master

import math
def my_round(i):
  f = math.floor(i)
  return f if i - f < 0.5 else f+1
meal_cgm_master['val'] = [my_round(i) for i in meal_cgm_master['val']]

meal_cgm_master

import collections
dict_bs = collections.Counter([(i,j) for i,j in zip(meal_cgm_master['B_min'],meal_cgm_master['B_max'])])
print(dict_bs)

dict_bs2 = collections.Counter([(i,j,k) for i,j,k in zip(meal_cgm_master['B_min'],meal_cgm_master['B_max'],meal_cgm_master['val'])])
dict_bs2

dict_bs3 = {}
for i in dict_bs2.keys():
  dict_bs3[i] = dict_bs2[i]/dict_bs[(i[0],i[1])]
new_sorted = sorted(dict_bs3,key=lambda x:dict_bs3[x],reverse=True)#last csv
Largest_confidence_rules = []
Most_frequent_setlist = []
for i in new_sorted:
  if dict_bs3[i]==1.0:
    Largest_confidence_rules.append(i)
new_sorted2 = sorted(dict_bs2,key=lambda x:dict_bs2[x],reverse=True)#most frequent
for i in new_sorted2:
    if dict_bs2[i]==9:
      Most_frequent_setlist.append(i)
print(Largest_confidence_rules) 
print(Most_frequent_setlist)
#print(new_sorted)
#print(new_sorted2)

#CSV With Most Frequent Sets
df_mostfrequent = DataFrame()
df_mostfrequent['Most Frequent Rules/Sets'] = Most_frequent_setlist
df_largestConfidence = DataFrame()
df_largestConfidence['Largest Confidence Rules/Sets'] = Largest_confidence_rules

df_mostfrequent.to_csv('Most Frequent Sets.csv', index=False)
df_largestConfidence.to_csv('Largest Confidence Sets.csv', index=False)

count=[]
for i in  new_sorted:
  if(dict_bs3[i]<0.15):
    count.append(i)
sorted_sets = sorted(count)
print(sorted_sets)

df_anomolousRules = DataFrame()
df_anomolousRules['Rules with Confidence < 15 %'] = sorted_sets

df_anomolousRules.to_csv('Confidence < 15% Sets.csv', index=False)